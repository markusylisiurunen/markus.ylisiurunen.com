---
title: "Understanding Gradient Descent in Neural Networks"
---

import Cite from "../../src/components/Cite"
import Image from "../../src/components/Image"
import Latex from "../../src/components/Latex"
import Reference from "../../src/components/Reference"

import MNISTCanvas from "../../src/components/MNISTCanvas"

<!-- Content -->

<MNISTCanvas width={400} height={400} />

I spent the last year trying to digest a lot of new information at Aalto
University while doing my master's degree in Machine Learning and Artificial
Intelligence. Even though the topics varied a lot from pure math to statistical
modeling with Stan to implementing deep neural networks for machine translation,
I feel like I didn't have a lot of time to simply stop and experiment with the
topics I was studying.

I decided to go back to the fundamentals and work up from there. I was always
fascinated by the way we optimize neural networks and more specifically,
gradient descent. The basic principles are so simple yet so powerful. The
state-of-the-art neural networks are practically all using the same principles
to train themselves.

In this blog post, we will try to understand what gradient descent is, what it
is used for and how we might go around implementing it from stratch.

## Table of contents

1. [The problem](#the-problem)
2. [Gradient Descent for Linear Regression](#gradient-descent-for-linear-regression)
3. [Neural Networks](#neural-networks)
   1. [Topology of a Neural Network](#topology-of-a-neural-network)
   2. [Building Blocks](#building-blocks)
      1. [Linear Transformation](#linear-transformation)
      2. [Activation Function](#activation-function)
   3. [Training](#training)
4. [Implementing a Linear Transformation Layer](#implementing-a-linear-transformation-layer)
5. [Using MLP for Regression](#using-mlp-for-regression)

## The problem

So, before trying to find a solution, we have to understand the problem. Our
goal is to somehow learn from given data points and find a somewhat optimal set
of parameters that describe the data reasonably well. In other words, our goal
is to learn from data points in such a way that it generalizes to unseen data
points in the future.

It's easier to understand this with an example. So, let's demonstrate this with
linear regression. First, we need our data.

```python:create-linear-regression-data.py
def create_linear_regression_data():
    x = np.arange(0, 10, 1)
    y = x + np.random.normal(0, 1, 10)

    return [x, y]

linear_regression_data = create_linear_regression_data()

plt.scatter(
    linear_regression_data[0],
    linear_regression_data[1],
);
```

The results from running the code above should look something like the scatter
plot below.

<Image
  src="/media/blog/understanding-gradient-descent/linear-regression-data.png"
  alt="Figure 1. Generated data for linear regression."
/>

The data is generated from the equation of a line with some added Gaussian noise
to make it look somewhat random.

<Latex block>{`f(x) = kx + b + z_i`}</Latex>
<Latex block>{`z_i \\sim N(0, 1)`}</Latex>

Now, we are interested in trying to find the optimal line that would represent
the data points the best. Let's try to do this by hand first.

<p>
  A line can be represented with two parameters, <Latex>k</Latex> and{" "}
  <Latex>b</Latex>. We need some sort of an initial guess for these. Let's say
  we think <Latex>k = 0.5</Latex> and <Latex>b = 1</Latex> could be somewhat
  close.
</p>

<Image
  src="/media/blog/understanding-gradient-descent/linear-regression-guess-1.png"
  alt="Figure 2. The first guess for the line's parameters."
/>

As we can see, it's not quite there yet but it's not too far away either. Are we
happy with the fit? No. So, we need to tune the parameters a bit in the right
direction to get it closer to the optimal values.

<p>
  The equation of a line is probably quite familiar to all of us and we have a
  good understanding of how the parameters affect the line. Therefore, we can
  come up with a better guess. Let's say we think that <Latex>k = 0.8</Latex>{" "}
  and <Latex>b = 0.5</Latex> would yield a better fit.
</p>

<Image
  src="/media/blog/understanding-gradient-descent/linear-regression-guess-2.png"
  alt="Figure 3. The second guess for the line's parameters."
/>

That's already much better and it only took us two tries. We could continue to
iterate on the parameter values and find an even better fit. But for now, we'll
consider this to be good enough for the demonstration.

There was one critical thing that wasn't quite clear to where it came from. How
did we know which direction we needed to tune the parameters? It was based on
our understanding of the equation of a line but could we somehow formulate this
into a mathematical form?

## Gradient descent for linear regression

First of all, we have to somehow define what makes a good fit to the given data
points. This is called the loss function and our goal is to minimize the loss by
tuning the parameters to the right direction. We'll be using a simple Mean
Square Error (MSE) loss function for our purposes.

<Latex block>
  {`
  \\begin{aligned}
    MSE & = \\frac{1}{n} \\sum_{i = 1}^{n} (y_i - \\hat{y_i})^2 \\\\
        & = \\frac{1}{n} \\sum_{i = 1}^{n} (y_i - (k x_i + b))^2 \\\\
        & = \\frac{1}{n} \\sum_{i = 1}^{n} (y_i - k x_i - b))^2
  \\end{aligned}
  `}
</Latex>

Effectively, we are just computing the sum of each data point's vertical
distance, or residual, to the fitted line.

Now, our goal is to minimize this loss as that would mean our line is as close
to the data points as possible. How do we do that? We compute the gradient of
the loss with respect to all parameters.

In order to be able to compute this, we need to use the chain rule. As a quick
reminder, I've written it out below.

<Latex block>{`f(g(x)) = f^{\\prime}(g(x)) g^{\\prime}(x)`}</Latex>

<Latex block>
  {`\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}`}
</Latex>

<p>
  Now, let's compute the derivative of the loss w.r.t. <Latex>k</Latex>.
</p>

<Latex block>
  {`
  \\begin{aligned}
    \\frac{\\partial}{\\partial k} MSE & = \\frac{1}{n} \\sum_{i = 1}^{n} 2 (y_i - \\hat{y_i}) \\cdot -x_i \\\\
                                       & = \\frac{-2}{n} \\sum_{i = 1}^{n} x_i (y_i - \\hat{y_i})
  \\end{aligned}
  `}
</Latex>

<p>
  And now let's do the same to compute the derivative of the loss w.r.t.{" "}
  <Latex>b</Latex>.
</p>

<Latex block>
  {`
  \\begin{aligned}
    \\frac{\\partial}{\\partial b} MSE = \\frac{-2}{n} \\sum_{i = 1}^{n} (y_i - \\hat{y_i})
  \\end{aligned}
  `}
</Latex>

We are now able to compute the gradient of the loss at any point w.r.t. both
parameters of the equation. We should now have some understanding of the
"gradient" part of gradient descent. Let's move to the "descent" part next.

The idea is to keep tweaking the parameters until we have come close enough to
the minimum of the loss function. How do we know where the minimum is? We keep
computing the gradient and always moving to the direction that minimizes the
function!

To visualize this, let's consider a simple quadratic function

<Latex block>{`g(x) = x^2`}</Latex>

<Image
  src="/media/blog/understanding-gradient-descent/quadratic-plot.png"
  alt="Figure 4. Plot of the quadratic function."
/>

<p>
  I've picked a single point at <Latex>c = -4</Latex> and visualised the
  gradient at that point. Our goal is the optimize the hypothetical parameter{" "}
  <Latex>c</Latex> so that we achieve the minimum of the fictional loss function
  of <Latex>g(c)</Latex>.
</p>

<p>
  We can do this by computing the gradient at <Latex>c</Latex> and stepping in
  the direction of the negative gradient. So, a single step could be something
  like the following.
</p>

<Latex block>{`c_{i + 1} = c_i - \\alpha \\cdot g^{\\prime}(c_i)`}</Latex>

<p>
  where <Latex>\alpha</Latex> is the learning rate. Take a look at the
  semi-pseudo code and the animation below.
</p>

```python:quadratic-gradient-descent.py
# Initialise the learning rate and the parameter
alpha = 0.05
c = -4

def do_epoch():
    grad_at_c = 2 * c
    c = c - alpha * grad_at_c

for i in range(50):
    plot()
    do_epoch()
```

<Image
  src="/media/blog/understanding-gradient-descent/quadratic-gradient-descent-animation.gif"
  alt="Figure 5. Animation of gradient descent for quadratic function."
/>

The same can be done for linear regression. I've done a similar example
visualisation shown below.

<Image
  src="/media/blog/understanding-gradient-descent/linear-regression-gradient-descent-animation.gif"
  alt="Figure 6. Animation of gradient descent for linear regression."
/>

The steps of gradient descent can be summarized as

1. Define a loss function
2. Compute the gradient of the loss w.r.t. the parameters
3. Apply <Latex>n</Latex> iterations (epochs) of optimization steps

## Neural Networks

In this section we will briefly introduce the topology of our toy-ish neural
network, its building blocks and see how these can be trained.

### Topology of a Neural Network

We will only focus on fully connected neural networks. There are tons of
different variations and architectures out there that are much more
sophisticated than our examples in this blog post. However, they are not that
relevant to the topic of this blog post so we will stick with a simple fully
connected architecture.

A fully connected neural network with two hidden layers might look something
like the following.

<Image
  src="/media/blog/understanding-gradient-descent/fully-connected-topology.png"
  alt="Figure 7. Topology of a fully connected network."
/>

The left-most layer is the input layer and the right-most layer is the output
layer. In other words, we have 4-dimensional inputs and we want 2-dimensional
outputs, for example, for classification purposes. The layers in the middle are
the hidden layers.

### Building Blocks

This section will zoom in to a single block from Figure 7 and describe what it
is composed of. A visualisation of a single block can be seen below.

<Image
  src="/media/blog/understanding-gradient-descent/linear-layer.png"
  alt="Figure 8. A single block of a fully connected neural network."
/>

#### Linear Transformation

<p>
  The linear transformation is a simple operation that applies a weight to each
  input and a bias term. This is similar to what we did before for the line,
  however, now we are doing this in <Latex>n</Latex>-dimensional space instead
  of 1-dimensional space.
</p>

The linear transformation can be formulated as

<Latex block>{`z = W^T x + b`}</Latex>

<p>
  where <Latex>W</Latex> is the weight vector and <Latex>b</Latex> is the bias
  term. We will need the gradient of the linear transformation later on, so
  let's calculate that as well.
</p>

<Latex block>{`\\frac{\\partial z}{\\partial x} = W`}</Latex>

<Latex block>{`\\frac{\\partial z}{\\partial W} = x`}</Latex>

<Latex block>{`\\frac{\\partial z}{\\partial b} = 1`}</Latex>

#### Activation function

There are multiple possible activation functions that are widely used but we
will focus on probably the simplest one called ReLU. The actual reason for why
we even need a non-linear activation function is left out on purpose as it's not
relevant to the topic of this blog post.

ReLU is defined as

<Latex block>{`y = max(0, z)`}</Latex>

and its derivative is simply

<Latex block>
  {`
  \\frac{\\partial y}{\\partial z} =
    \\begin{cases}
      0 &\\text{if } z < 0 \\\\
      1 &\\text{if } z > 0
    \\end{cases}
  `}
</Latex>

### Training

Remember the chain rule I mentioned before? Great, that's going to be very
useful now.

So, let's start from a single block in our neural network. After combining the
two steps from above, it is defined as

<Latex block>{`y = max(0, W^T x + b)`}</Latex>

The chain rule stated that we can split the derivative into two separate steps
and multiply them by each other. Let's see how that works in our case.

<Latex block>
  {`
  \\frac{\\partial y}{\\partial x} = \\frac{\\partial y}{\\partial z} \\cdot \\frac{\\partial z}{\\partial x}
                                   = \\begin{cases}
                                       0 &\\text{if } z < 0 \\\\
                                       W &\\text{if } z > 0
                                     \\end{cases}
  `}
</Latex>

We can now calculate the derivative of a single block's output w.r.t. its inputs
in our neural network. However, we are really interested in computing the loss
function's derivative w.r.t. the inputs of the entire network.

The training progresses in two phases:

1. Forward pass where we pass an input through the network
2. Backward pass where we propagate the gradient from the output to the input

<p>
  The result that we got above requires us to know the value of <Latex>z</Latex>{" "}
  in order to be able to compute the gradient. However, this is not a problem as
  we know the value after the forward pass.
</p>

<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />

First, we need some sort of an initial guess as the baseline for finding a
better set of

Now, we would like to find the optimal line that represents this dataset as well
as possible. Let's try to do this by hand first.

The first step is to somehow get an initial guess of what could be the right
equation. We all know that a line can be prepresented as follows.

<Latex block>{`f(x)=kx+b`}</Latex>

<p>
  In other words, we need to find the optimal values for <Latex>k</Latex> and{" "}
  <Latex>b</Latex>. Let's start with <Latex>k=0.5</Latex> and <Latex>b=1</Latex>
  .
</p>

<img src="/media/blog/understanding-gradient-descent/linear-regression-guess-1.png" />

Not quite the right values, as we can see. So, what can we do to fix this? Maybe
we could just tune the parameters a bit to make it closer to the optimal value?
Let's do just that!

<p>
  This time, we'll go with <Latex>k=0.8</Latex> and <Latex>b=0.5</Latex>.
</p>

<img src="/media/blog/understanding-gradient-descent/linear-regression-guess-2.png" />

Much better! But still not quite there. However, this time we probably would not
make such a big adjustment at once as we might easily overdo it. We'd tweak just
a little bit to make it closer to the optimal value.

What we just did, is very much what gradient descent does to a neural network's
parameters. It looks at the output, tries to figure out which direction it
should tweak them and does a small step to that direction. One round might not
be enough, so this is repeated a number of times.

## What is gradient descent?

So, we'll

<p>
  Before going into any deeper, we need to understand what gradient descent is.{" "}
  <Cite id="wikipedia-gd" /> Let's see what Wikipedia has to say about it:
</p>

> Gradient descent is a first-order iterative optimization algorithm for finding
> a local minimum of a differentiable function.
>
> Source: [Wikipedia](https://wikipedia.com)

<Latex block>{`\\sum_{i = 0}^{n} = x_{i}`}</Latex>

```js:hello.js
import React from "react"

function HelloWorld() {
  return <p>Hello, world!</p>
}

export default HelloWorld
```

## References

<Reference
  id="wikipedia-gd"
  author="Markus Ylisiurunen"
  url="https://google.com"
/>
<Reference id="wiki" author="Markus Ylisiurunen" url="https://google.com" />
